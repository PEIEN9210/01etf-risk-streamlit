# -*- coding: utf-8 -*-
"""app.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Y1jRJvzhlUjdd66vnUOBj57YzwXHYc1s
"""

# app.py
# -*- coding: utf-8 -*-
# -*- coding: utf-8 -*-

import streamlit as st
import pandas as pd
import numpy as np
import yfinance as yf
from datetime import datetime, timedelta
from scipy.stats import spearmanr
import plotly.graph_objects as go
import altair as alt

# ===============================
# åŸºæœ¬è¨­å®š
# ===============================
st.set_page_config(page_title="å°ç£ ETF å€‹äººåŒ–æ¨è–¦ç³»çµ±", layout="wide")

# ===============================
# å¸¸æ•¸
# ===============================
TRADING_DAYS = 252
RISK_FREE_RATE = 0.8
ALPHA_MODEL = 0.5
TOP_N = 10

# ===============================
# æŒ‡æ¨™è¨ˆç®—
# ===============================
def calc_metrics(df, market_df):
    r = df["Close"].pct_change().dropna()
    mr = market_df["Close"].pct_change().dropna()
    idx = r.index.intersection(mr.index)
    r, mr = r.loc[idx], mr.loc[idx]
    ann_ret = r.mean() * TRADING_DAYS
    ann_vol = r.std() * np.sqrt(TRADING_DAYS)
    sharpe = (ann_ret - RISK_FREE_RATE) / ann_vol if ann_vol>0 else 0
    beta = np.cov(r, mr)[0,1] / np.var(mr) if np.var(mr) > 0 else 0
    return ann_ret*100, ann_vol*100, sharpe, beta

def compute_hot_index(df, window=20):
    volume_ma = df["Volume"].rolling(window).mean().iloc[-1]
    returns = df["Close"].pct_change()
    volatility = returns.rolling(window).std().iloc[-1]
    flow_proxy = (df["Close"]*df["Volume"]).rolling(window).mean().iloc[-1]
    return {"volume_score": volume_ma, "volatility": volatility, "flow_proxy": flow_proxy}

def robust_zscore(series):
    med = np.median(series)
    mad = np.median(np.abs(series - med))
    if mad == 0:
        return pd.Series(0, index=series.index)
    return (series - med)/mad

def compute_personalized_score(ann_ret, ann_vol, sharpe, beta, theta):
    expected_return = 5 + theta * 20
    acceptable_vol = 10 + theta * 25
    ideal_beta = 0.7 + theta * 0.8
    sharpe_fit = min(sharpe/3,1)
    return_fit = np.clip(1 - abs(ann_ret - expected_return)/expected_return,0,1)
    vol_fit = np.clip(1 - ann_vol/acceptable_vol,0,1)
    beta_fit = np.clip(1 - abs(beta - ideal_beta)/ideal_beta,0,1)
    personal_score = np.mean([sharpe_fit, return_fit, vol_fit, beta_fit])
    return {"personal_score": personal_score, "sharpe_fit":sharpe_fit, "return_fit":return_fit,
            "vol_fit":vol_fit,"beta_fit":beta_fit}

def compute_final_score(hot_index_norm, personal_score, alpha):
    return alpha*hot_index_norm + (1-alpha)*personal_score

# ===============================
# V2 Extensionï¼šHumanâ€“Asset Matching
# ===============================
V2_HORIZONS = {
    "1y": {"period": "1y", "weight": 0.5},
    "3y": {"period": "3y", "weight": 0.3},
    "5y": {"period": "5y", "weight": 0.2},
}

# ===============================
# ä¿®æ­£ç‰ˆ fetch_dividend_info
# ===============================
def fetch_dividend_info(etf):
    try:
        # æ¨¡æ“¬æŠ“è³‡æ–™
        return {
            "æœ€æ–°é…æ¯æ—¥": "2025-12-31",
            "æœ€è¿‘ä¸€æ¬¡é…æ¯": 0.8,
            "TTMé…æ¯": 1.5,
            "TTMæ®–åˆ©ç‡%": 2.3
        }
    except Exception as e:
        st.warning(f"æŠ“å–é…æ¯è³‡æ–™å¤±æ•—: {etf} / {e}")
        return {"æœ€æ–°é…æ¯æ—¥":None,"æœ€è¿‘ä¸€æ¬¡é…æ¯":0,"TTMé…æ¯":0,"TTMæ®–åˆ©ç‡%":0}

# ===============================
# ä¸»æµç¨‹
# ===============================

# å‡è¨­ ETF_LIST èˆ‡ MARKET_BENCHMARK å·²å®šç¾©
# price_data = fetch_all_price_data(ETF_LIST, MARKET_BENCHMARK)
# ä»¥ä¸‹ç¤ºç¯„ç‚ºç©º dictï¼Œå¯¦å‹™éœ€è‡ªè¡ŒæŠ“è³‡æ–™
ETF_LIST = {"0050":"æŒ‡æ•¸å‹","0056":"é«˜è‚¡æ¯"}
MARKET_BENCHMARK = "TWII"
theta = 0.5

price_data = {}  # ç”¨æˆ¶éœ€è‡ªè¡Œæä¾› fetch_all_price_data
market_df = price_data.get(MARKET_BENCHMARK, pd.DataFrame({"Close":[],"Volume":[]}))
if market_df.empty:
    market_df = pd.DataFrame({"Close":[100,101,102],"Volume":[1000,1200,1100]},
                             index=pd.date_range("2025-01-01", periods=3))

rows=[]
for etf, etf_type in ETF_LIST.items():
    df = price_data.get(etf, market_df)  # ç¤ºç¯„ä½¿ç”¨ market_df
    if df is None or market_df is None:
        continue
    ann_ret, ann_vol, sharpe, beta = calc_metrics(df, market_df)
    comp = compute_personalized_score(ann_ret, ann_vol, sharpe, beta, theta)
    risk_score = comp["vol_fit"]*0.4 + comp["beta_fit"]*0.3 + comp["return_fit"]*0.2 + comp["sharpe_fit"]*0.1
    div_info = fetch_dividend_info(etf)
    hot_metrics = compute_hot_index(df)
    row = {"ETF":etf, "é¡å‹":etf_type, "æœ€æ–°åƒ¹":round(df["Close"].iloc[-1],2),
           "æœ€æ–°é…æ¯æ—¥": div_info["æœ€æ–°é…æ¯æ—¥"], "æœ€è¿‘ä¸€æ¬¡é…æ¯":div_info["æœ€è¿‘ä¸€æ¬¡é…æ¯"],
           "TTMé…æ¯":div_info["TTMé…æ¯"], "TTMæ®–åˆ©ç‡%":div_info["TTMæ®–åˆ©ç‡%"],
           "Sharpe":round(sharpe,2),"Beta":round(beta,2),"å¹´åŒ–å ±é…¬%":round(ann_ret,2),
           "å¹´åŒ–æ³¢å‹•%":round(ann_vol,2),"å€‹äººåŒ–åˆ†æ•¸":round(comp["personal_score"],3),
           "é¢¨éšªé©é…åˆ†æ•¸":round(risk_score,3),
           "volume_score":hot_metrics["volume_score"], "volatility":hot_metrics["volatility"],
           "flow_proxy":hot_metrics["flow_proxy"],
           "Sharpeé©é…":round(comp["sharpe_fit"],2), "å ±é…¬é©é…":round(comp["return_fit"],2),
           "æ³¢å‹•é©é…":round(comp["vol_fit"],2), "Betaé©é…":round(comp["beta_fit"],2)}
    rows.append(row)

df_all = pd.DataFrame(rows)
df_all["hot_index"] = df_all["volume_score"] + df_all["flow_proxy"] - df_all["volatility"]
df_all["hot_index_norm"] = robust_zscore(df_all["hot_index"]).fillna(0)

# ===============================
# Ranking by Î¸
# ===============================
THETA_LIST = [0.0,0.25,0.5,0.75,1.0]
theta_rankings = {}

for t in THETA_LIST:
    rows_theta=[]
    for etf, etf_type in ETF_LIST.items():
        df = price_data.get(etf, market_df)
        if df is None or market_df is None:
            continue
        ann_ret, ann_vol, sharpe, beta = calc_metrics(df, market_df)
        comp = compute_personalized_score(ann_ret, ann_vol, sharpe, beta, t)
        final_score = compute_final_score(df_all.loc[df_all["ETF"]==etf,"hot_index_norm"].values[0],
                                          comp["personal_score"], ALPHA_MODEL)
        base_row = df_all[df_all["ETF"]==etf].iloc[0]
        row = {"ETF":etf,"é¡å‹":etf_type,"Î¸":t,"æœ€æ–°åƒ¹":base_row["æœ€æ–°åƒ¹"],
               "æœ€æ–°é…æ¯æ—¥":base_row["æœ€æ–°é…æ¯æ—¥"],"æœ€è¿‘ä¸€æ¬¡é…æ¯":base_row["æœ€è¿‘ä¸€æ¬¡é…æ¯"],
               "TTMé…æ¯":base_row["TTMé…æ¯"],"TTMæ®–åˆ©ç‡%":base_row["TTMæ®–åˆ©ç‡%"],
               "final_score":final_score,**comp,"hot_index":base_row["hot_index"]}
        rows_theta.append(row)
    df_theta = pd.DataFrame(rows_theta).sort_values("final_score",ascending=False)
    theta_rankings[t] = df_theta

theta_display_closest = min(THETA_LIST,key=lambda x: abs(x-theta))
df_ui = theta_rankings[theta_display_closest].head(TOP_N)
if market_df is not None and len(market_df)>0:
    last_price_time = market_df.index[-1]
    st.caption(f"ğŸ“… åƒ¹æ ¼è³‡æ–™æ™‚é–“ï¼š{last_price_time}")

# ===============================
# é›·é”åœ–å°ˆç”¨è³‡æ–™
# ===============================
radar_metrics = ["sharpe_fit", "return_fit", "vol_fit", "beta_fit"]
df_radar = df_ui.copy()
for col in radar_metrics:
    df_radar[col] = df_radar[col].fillna(0.5)
    min_v = df_radar[col].min()
    max_v = df_radar[col].max()
    if max_v > min_v:
        df_radar[col] = (df_radar[col] - min_v) / (max_v - min_v)
    else:
        df_radar[col] = 0.5

# ===============================
# Top-N è¡¨æ ¼
# ===============================
st.subheader(f"ğŸ¯ Top {TOP_N} ETF æ’åºï¼ˆÎ¸={round(theta,2)}, final_scoreï¼‰")
st.dataframe(df_ui[["ETF","é¡å‹","æœ€æ–°åƒ¹","æœ€æ–°é…æ¯æ—¥","æœ€è¿‘ä¸€æ¬¡é…æ¯",
                    "TTMé…æ¯","TTMæ®–åˆ©ç‡%","final_score","personal_score",
                    "sharpe_fit","return_fit","vol_fit","beta_fit","hot_index"]],
             use_container_width=True)

# ===============================
# Top-N é›·é”åœ– (Plotly)
# ===============================
st.subheader(f"ğŸ•¸ï¸ Top {TOP_N} ETF å¤šæŒ‡æ¨™é›·é”åœ–")
radar_labels = ["Sharpe", "Return", "Volatility", "Beta"]
fig = go.Figure()
for _, row in df_radar.iterrows():
    values = [row[m] for m in radar_metrics]
    values.append(values[0])
    fig.add_trace(go.Scatterpolar(
        r=values,
        theta=radar_labels + [radar_labels[0]],
        fill="toself",
        name=row["ETF"],
        opacity=0.6
    ))
fig.update_layout(
    polar=dict(
        radialaxis=dict(visible=True, range=[0, 1])
    ),
    showlegend=True,
    margin=dict(l=40, r=40, t=40, b=60)
)
st.plotly_chart(fig, use_container_width=True)

# ===============================
# Top-N æ°£æ³¡åœ– (Altair)
# ===============================
st.subheader(f"ğŸ’­ Top {TOP_N} ETF æ°£æ³¡åœ–ï¼ˆÎ¸={round(theta,2)}ï¼‰")
bubble = alt.Chart(df_ui).mark_circle(opacity=0.7, stroke="black", strokeWidth=0.5).encode(
    x=alt.X("sharpe_fit:Q", title="Sharpe é©é…"),
    y=alt.Y("personal_score:Q", title="å€‹äººåŒ–åˆ†æ•¸"),
    size=alt.Size("beta_fit:Q", title="Beta é©é…", scale=alt.Scale(range=[100,1600])),
    color=alt.Color("é¡å‹:N", title="ETF é¡å‹"),
    tooltip=["ETF","sharpe_fit","return_fit","vol_fit","beta_fit",
             "personal_score","hot_index","final_score"]
)
st.altair_chart(bubble, use_container_width=True)

# ===============================
# V2-1 éç·šæ€§è·é›¢ï¼ˆGaussian Fitï¼‰
# ===============================
def gaussian_fit(x, mu, sigma):
    if sigma <= 0:
        return 0.0
    return np.exp(-0.5 * ((x - mu) / sigma) ** 2)

def nonlinear_personal_score(row, theta):
    mu_ret = 5 + theta * 20
    mu_vol = 10 + theta * 25
    mu_beta = 0.7 + theta * 0.8

    ret_score = gaussian_fit(row["å¹´åŒ–å ±é…¬%"], mu_ret, mu_ret * 0.5)
    vol_score = gaussian_fit(row["å¹´åŒ–æ³¢å‹•%"], mu_vol, mu_vol * 0.5)
    beta_score = gaussian_fit(row["Beta"], mu_beta, mu_beta * 0.5)
    sharpe_score = np.tanh(row["Sharpe"] / 2)

    return np.mean([ret_score, vol_score, beta_score, sharpe_score])

def multi_period_return(df):
    closes = df["Close"]
    periods = {"3M": 63, "6M": 126, "12M": 252}
    rets = {}
    for k, p in periods.items():
        rets[k] = closes.iloc[-1]/closes.iloc[-p]-1 if len(closes) >= p else np.nan
    weights = {"3M":0.5,"6M":0.3,"12M":0.2}
    weighted_ret = sum(rets[k]*weights[k] for k in rets if not np.isnan(rets[k]))
    return weighted_ret*100

def risk_distribution_metrics(df):
    r = df["Close"].pct_change().dropna()
    downside = r[r<0]
    downside_vol = downside.std()*np.sqrt(TRADING_DAYS) if len(downside)>0 else 0
    var_95 = np.percentile(r,5)
    cvar_95 = r[r<=var_95].mean() if len(r[r<=var_95])>0 else 0
    return downside_vol*100, cvar_95*100

v2_rows=[]
for _, row in df_all.iterrows():
    etf = row["ETF"]
    df = price_data.get(etf, market_df)
    if df is None:
        continue
    v2_score = nonlinear_personal_score(row, theta)
    mp_ret = multi_period_return(df)
    downside_vol, cvar_95 = risk_distribution_metrics(df)
    v2_rows.append({
        "ETF": etf,
        "V2_éç·šæ€§åˆ†æ•¸": round(v2_score,3),
        "V2_å¤šæœŸé–“åŠ æ¬Šå ±é…¬%": round(mp_ret,2),
        "V2_ä¸‹è¡Œæ³¢å‹•%": round(downside_vol,2),
        "V2_CVaR_95%": round(cvar_95,2)
    })

df_v2 = pd.DataFrame(v2_rows)
df_all = df_all.merge(df_v2, on="ETF", how="left")

st.markdown("---")
st.subheader("ğŸ§ª V2 é€²éšåˆ†æï¼ˆéç·šæ€§ Ã— å¤šæœŸé–“ Ã— é¢¨éšªåˆ†å¸ƒï¼‰")
st.caption("âš ï¸ ä»¥ä¸‹ç‚º V2 åˆ†ææ¨¡çµ„ï¼Œä¸å½±éŸ¿ä»»ä½• V1 æ’åºèˆ‡æ¨è–¦çµæœ")
st.dataframe(df_all[[
    "ETF","V2_éç·šæ€§åˆ†æ•¸","V2_å¤šæœŸé–“åŠ æ¬Šå ±é…¬%","V2_ä¸‹è¡Œæ³¢å‹•%","V2_CVaR_95%"
]], use_container_width=True)
