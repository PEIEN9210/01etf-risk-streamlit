# -*- coding: utf-8 -*-
"""app.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Y1jRJvzhlUjdd66vnUOBj57YzwXHYc1s
"""

# app.py 
# -*- coding: utf-8 -*-

import streamlit as st
import pandas as pd
import numpy as np
import yfinance as yf
from datetime import datetime, timedelta
from scipy.stats import spearmanr
import plotly.graph_objects as go
import altair as alt
@st.cache_data(ttl=3600)
def fetch_dividend_info(etf_code):
    """
    å¤šå±¤æ¬¡è³‡æ–™ä¾†æºç­–ç•¥
    
    å„ªå…ˆé †åºï¼š
    1. FinMind APIï¼ˆæœ€å¯é ï¼‰
    2. è­‰äº¤æ‰€ API
    3. Yahoo Finance
    4. éœæ…‹è³‡æ–™ï¼ˆæ‰‹å‹•ç¶­è­·ï¼‰
    """
    stock_code = etf_code.replace('.TW', '')
    
    # ç¬¬ä¸€å±¤ï¼šFinMind
    try:
        result = fetch_dividend_info_finmind(etf_code)
        if result["æœ€æ–°é…æ¯æ—¥"] is not None:
            return result
    except Exception as e:
        pass
    
    # ç¬¬äºŒå±¤ï¼šè­‰äº¤æ‰€
    try:
        result = fetch_dividend_info_twse(etf_code)
        if result["æœ€æ–°é…æ¯æ—¥"] is not None:
            return result
    except Exception as e:
        pass
    
    # ç¬¬ä¸‰å±¤ï¼šYahoo Finance
    try:
        result = fetch_dividend_fallback(stock_code)
        if result["æœ€æ–°é…æ¯æ—¥"] is not None:
            return result
    except Exception as e:
        pass
    
    # æœ€çµ‚å±¤ï¼šéœæ…‹è³‡æ–™
    return get_static_dividend_data(stock_code)

ğŸ”§ å®Œæ•´ä¿®æ­£å¾Œçš„ç¨‹å¼ç¢¼
å°‡æ‚¨çš„ç¨‹å¼ç¢¼ä¸­çš„ fetch_dividend_info å‡½æ•¸æ›¿æ›ç‚ºï¼š
pythonimport requests
from datetime import datetime, timedelta

# ===============================
# é…æ¯è³‡æ–™æŠ“å–ï¼ˆæ”¹è‰¯ç‰ˆï¼‰
# ===============================

@st.cache_data(ttl=3600)  # å¿«å– 1 å°æ™‚
def fetch_dividend_info(etf_code):
    """
    å¤šå±¤æ¬¡è³‡æ–™ä¾†æºç­–ç•¥æŠ“å– ETF é…æ¯è³‡æ–™
    """
    stock_code = etf_code.replace('.TW', '')
    
    # å„ªå…ˆä½¿ç”¨ FinMind API
    try:
        url = "https://api.finmindtrade.com/api/v4/data"
        params = {
            "dataset": "TaiwanStockDividend",
            "data_id": stock_code,
            "start_date": (datetime.now() - timedelta(days=400)).strftime('%Y-%m-%d'),
            "token": ""
        }
        
        response = requests.get(url, params=params, timeout=10)
        
        if response.status_code == 200:
            data = response.json()
            
            if data.get('status') == 200 and data.get('data'):
                df = pd.DataFrame(data['data'])
                
                if not df.empty:
                    df['date'] = pd.to_datetime(df['date'])
                    df = df.sort_values('date', ascending=False)
                    
                    # è¨ˆç®— TTMï¼ˆéå» 12 å€‹æœˆï¼‰
                    one_year_ago = datetime.now() - timedelta(days=365)
                    ttm_df = df[df['date'] >= one_year_ago]
                    ttm_sum = ttm_df['cash_dividend'].astype(float).sum()
                    
                    # å–å¾—æœ€æ–°åƒ¹æ ¼
                    latest_price = fetch_latest_price(etf_code)
                    if latest_price is None:
                        latest_price = 100  # é è¨­å€¼é¿å…é™¤é›¶
                    
                    ttm_yield = (ttm_sum / latest_price * 100) if latest_price > 0 else 0
                    
                    return {
                        "æœ€æ–°é…æ¯æ—¥": df.iloc[0]['date'].date(),
                        "æœ€è¿‘ä¸€æ¬¡é…æ¯": round(float(df.iloc[0]['cash_dividend']), 3),
                        "TTMé…æ¯": round(ttm_sum, 3),
                        "TTMæ®–åˆ©ç‡%": round(ttm_yield, 2)
                    }
    except Exception as e:
        # è¨˜éŒ„éŒ¯èª¤ä½†ä¸ä¸­æ–·æµç¨‹
        pass
    
    # å‚™ç”¨æ–¹æ¡ˆï¼šä½¿ç”¨éœæ…‹è³‡æ–™
    return get_static_dividend_data(stock_code)


def get_static_dividend_data(stock_code):
    """
    æ‰‹å‹•ç¶­è­·çš„éœæ…‹é…æ¯è³‡æ–™
    å»ºè­°æ¯å­£æ›´æ–°ä¸€æ¬¡
    """
    # 2024 Q4 è³‡æ–™ï¼ˆè«‹æ ¹æ“šå¯¦éš›æƒ…æ³æ›´æ–°ï¼‰
    static_data = {
        "0050": {
            "æœ€æ–°é…æ¯æ—¥": datetime(2024, 7, 22).date(),
            "æœ€è¿‘ä¸€æ¬¡é…æ¯": 3.00,
            "TTMé…æ¯": 5.50,
            "TTMæ®–åˆ©ç‡%": 3.2
        },
        "0056": {
            "æœ€æ–°é…æ¯æ—¥": datetime(2024, 10, 22).date(),
            "æœ€è¿‘ä¸€æ¬¡é…æ¯": 2.20,
            "TTMé…æ¯": 4.40,
            "TTMæ®–åˆ©ç‡%": 6.8
        },
        "006208": {
            "æœ€æ–°é…æ¯æ—¥": datetime(2024, 7, 22).date(),
            "æœ€è¿‘ä¸€æ¬¡é…æ¯": 0.65,
            "TTMé…æ¯": 1.30,
            "TTMæ®–åˆ©ç‡%": 2.9
        },
        "00878": {
            "æœ€æ–°é…æ¯æ—¥": datetime(2024, 11, 22).date(),
            "æœ€è¿‘ä¸€æ¬¡é…æ¯": 0.38,
            "TTMé…æ¯": 1.52,
            "TTMæ®–åˆ©ç‡%": 7.2
        },
        "00919": {
            "æœ€æ–°é…æ¯æ—¥": datetime(2024, 10, 22).date(),
            "æœ€è¿‘ä¸€æ¬¡é…æ¯": 0.54,
            "TTMé…æ¯": 2.16,
            "TTMæ®–åˆ©ç‡%": 8.5
        },
        "00692": {
            "æœ€æ–°é…æ¯æ—¥": datetime(2024, 7, 22).date(),
            "æœ€è¿‘ä¸€æ¬¡é…æ¯": 0.48,
            "TTMé…æ¯": 0.96,
            "TTMæ®–åˆ©ç‡%": 3.1
        },
        "00757": {
            "æœ€æ–°é…æ¯æ—¥": datetime(2024, 8, 22).date(),
            "æœ€è¿‘ä¸€æ¬¡é…æ¯": 0.28,
            "TTMé…æ¯": 0.56,
            "TTMæ®–åˆ©ç‡%": 2.5
        }
    }
    
    return static_data.get(stock_code, {
        "æœ€æ–°é…æ¯æ—¥": None,
        "æœ€è¿‘ä¸€æ¬¡é…æ¯": 0.0,
        "TTMé…æ¯": 0.0,
        "TTMæ®–åˆ©ç‡%": 0.0
    })

ğŸ“Š åœ¨ Streamlit UI ä¸­é¡¯ç¤ºè³‡æ–™ä¾†æº
åŠ å…¥è³‡æ–™ä¾†æºèªªæ˜ï¼Œæé«˜é€æ˜åº¦ï¼š
python# åœ¨ä¸»æµç¨‹ä¸­åŠ å…¥è³‡æ–™ä¾†æºèªªæ˜
st.sidebar.markdown("---")
st.sidebar.header("ğŸ“¡ è³‡æ–™ä¾†æº")

with st.sidebar.expander("æŸ¥çœ‹è³‡æ–™ä¾†æºèªªæ˜"):
    st.caption(
        "**åƒ¹æ ¼è³‡æ–™**ï¼šYahoo Finance (å»¶é² 15 åˆ†é˜)\n\n"
        "**é…æ¯è³‡æ–™**ï¼š\n"
        "1. FinMind APIï¼ˆå„ªå…ˆï¼‰\n"
        "2. æ‰‹å‹•ç¶­è­·éœæ…‹è³‡æ–™ï¼ˆå‚™ç”¨ï¼‰\n\n"
        "**æ›´æ–°é »ç‡**ï¼šæ¯å°æ™‚æ›´æ–°ä¸€æ¬¡\n\n"
        "âš ï¸ **æ³¨æ„**ï¼šé…æ¯è³‡æ–™åƒ…ä¾›åƒè€ƒï¼Œå¯¦éš›é…æ¯ä»¥å„ ETF å…¬å‘Šç‚ºæº–"
    )

# ===============================
# åŸºæœ¬è¨­å®š
# ===============================
st.set_page_config(page_title="å°ç£ ETF å€‹äººåŒ–æ¨è–¦ç³»çµ±", layout="wide")
st.title("ğŸ“Š å°ç£ ETF å€‹äººåŒ– + ç†±é–€ ETF å¤šæº–å‰‡è³‡ç”¢æ’åºæ¡†æ¶")
st.caption("âš ï¸ æœ¬ç³»çµ±åƒ…ä¾›å­¸è¡“ç ”ç©¶åƒè€ƒï¼Œä¸æ§‹æˆæŠ•è³‡å»ºè­°ã€‚æŠ•è³‡æœ‰é¢¨éšªï¼Œè«‹å¯©æ…è©•ä¼°ã€‚")

TRADING_DAYS = 252
RISK_FREE_RATE = 0.01  # ç„¡é¢¨éšªåˆ©ç‡

# ===============================
# ETF Universe & å¸‚å ´åŸºæº–
# ===============================
ETF_LIST = {
    "0050.TW": "è‚¡ç¥¨å‹",
    "006208.TW": "è‚¡ç¥¨å‹",
    "00692.TW": "è‚¡ç¥¨å‹",
    "00757.TW": "è‚¡ç¥¨å‹",
    "0056.TW": "é«˜è‚¡æ¯å‹",
    "00878.TW": "é«˜è‚¡æ¯å‹",
    "00919.TW": "é«˜è‚¡æ¯å‹",
}
MARKET_BENCHMARK = "0050.TW"

# ===============================
# Sidebarï¼šé¢¨éšªåå¥½è©•ä¼°ï¼ˆSCF å•å·æ³•ï¼‰
# ===============================
st.sidebar.header("ğŸ‘¤ æŠ•è³‡äººé¢¨éšªåå¥½è©•ä¼°")
st.sidebar.markdown("**åŸºæ–¼ SCF Risk Tolerance Questionnaire**")
st.sidebar.caption("ç¾åœ‹è¯é‚¦å„²å‚™ç³»çµ±æ¶ˆè²»è€…è²¡å‹™èª¿æŸ¥æ¨™æº–å•å·")

# === Question 1: Investment Horizon ===
st.sidebar.markdown("---")
st.sidebar.subheader("Q1. æ‚¨çš„æŠ•è³‡æ™‚é–“ç¯„åœï¼Ÿ")
horizon_mapping = {
    "å°‘æ–¼ 1 å¹´": (0.5, 0.0),
    "1-3 å¹´": (2, 0.15),
    "4-6 å¹´": (5, 0.30),
    "7-10 å¹´": (8.5, 0.50),
    "10 å¹´ä»¥ä¸Š": (15, 0.70)
}
horizon_choice = st.sidebar.radio(
    "é¸æ“‡æŠ•è³‡æœŸé–“",
    list(horizon_mapping.keys()),
    index=3,  # é è¨­ 7-10 å¹´
    help="è¼ƒé•·çš„æŠ•è³‡æœŸé–“å…è¨±æ‰¿å—æ›´é«˜çš„çŸ­æœŸæ³¢å‹•"
)
horizon_years, horizon_score = horizon_mapping[horizon_choice]

# === Question 2: Risk Capacity (SCF Standard Question) ===
st.sidebar.markdown("---")
st.sidebar.subheader("Q2. å¦‚æœæ‚¨æœ‰ä¸€ç­†é–’ç½®è³‡é‡‘ï¼Œæ‚¨æœƒé¸æ“‡ï¼Ÿ")
risk_capacity_mapping = {
    "å­˜å…¥éŠ€è¡Œæˆ–è³¼è²·æ”¿åºœå…¬å‚µï¼ˆå¹¾ä¹ç„¡é¢¨éšªï¼‰": 0.0,
    "è³¼è²·å‚µåˆ¸å‹åŸºé‡‘ï¼ˆä½é¢¨éšªï¼Œå ±é…¬ç©©å®šï¼‰": 0.25,
    "è³¼è²·æ··åˆå‹åŸºé‡‘ï¼ˆä¸­ç­‰é¢¨éšªèˆ‡å ±é…¬ï¼‰": 0.50,
    "è³¼è²·è‚¡ç¥¨å‹åŸºé‡‘ï¼ˆé«˜é¢¨éšªï¼Œè¿½æ±‚é«˜å ±é…¬ï¼‰": 0.75,
    "è³¼è²·å€‹è‚¡æˆ–é«˜é¢¨éšªå•†å“ï¼ˆæ‰¿å—é‡å¤§è™§æé¢¨éšªï¼‰": 1.0
}
risk_capacity = st.sidebar.radio(
    "æŠ•è³‡åå¥½",
    list(risk_capacity_mapping.keys()),
    index=2,  # é è¨­æ··åˆå‹
    help="SCF æ¨™æº–å•é¡Œï¼šè©•ä¼°æ‚¨å°é¢¨éšªå ±é…¬çš„åŸºæœ¬æ…‹åº¦"
)
capacity_score = risk_capacity_mapping[risk_capacity]

# === Question 3: Loss Tolerance (Behavioral Finance Standard) ===
st.sidebar.markdown("---")
st.sidebar.subheader("Q3. å‡è¨­æ‚¨æŠ•è³‡çš„è³‡ç”¢åœ¨ä¸€å€‹æœˆå…§ä¸‹è·Œ 20%ï¼Œæ‚¨æœƒï¼Ÿ")
loss_tolerance_mapping = {
    "ç«‹å³å…¨éƒ¨è³£å‡ºï¼Œç„¡æ³•æ‰¿å—è™§æ": 0.0,
    "è³£å‡ºä¸€åŠï¼Œé™ä½é¢¨éšª": 0.20,
    "ç¶­æŒä¸å‹•ï¼Œç­‰å¾…åå½ˆ": 0.50,
    "å°å¹…åŠ ç¢¼ï¼Œé€¢ä½æ‰¿æ¥": 0.75,
    "å¤§å¹…åŠ ç¢¼ï¼Œèªç‚ºæ˜¯çµ•ä½³æ©Ÿæœƒ": 1.0
}
loss_tolerance = st.sidebar.radio(
    "å¸‚å ´ä¸‹è·Œåæ‡‰",
    list(loss_tolerance_mapping.keys()),
    index=2,  # é è¨­ç¶­æŒä¸å‹•
    help="è¡Œç‚ºé‡‘èå­¸æ¨™æº–å•é¡Œï¼šè©•ä¼°æ‚¨çš„æå¤±å­æƒ¡ç¨‹åº¦"
)
loss_score = loss_tolerance_mapping[loss_tolerance]

# === Question 4: Income Stability ===
st.sidebar.markdown("---")
st.sidebar.subheader("Q4. æ‚¨çš„æ”¶å…¥ç©©å®šæ€§ï¼Ÿ")
income_stability_mapping = {
    "éå¸¸ä¸ç©©å®šï¼ˆè‡ªç”±æ¥­ã€å‰µæ¥­ï¼‰": 0.0,
    "ä¸ç©©å®šï¼ˆæ¥­å‹™æ€§è³ªã€ä½£é‡‘åˆ¶ï¼‰": 0.25,
    "æ™®é€šï¼ˆå›ºå®šè–ªè³‡ä½†æœ‰è£å“¡é¢¨éšªï¼‰": 0.50,
    "ç©©å®šï¼ˆå…¬å‹™å“¡ã€å¤§ä¼æ¥­å“¡å·¥ï¼‰": 0.75,
    "éå¸¸ç©©å®šï¼ˆé€€ä¼‘é‡‘ã€ç§Ÿé‡‘æ”¶å…¥ï¼‰": 1.0
}
income_stability = st.sidebar.selectbox(
    "æ”¶å…¥ç‹€æ³",
    list(income_stability_mapping.keys()),
    index=2,  # é è¨­æ™®é€š
    help="æ”¶å…¥ç©©å®šæ€§å½±éŸ¿æ‚¨æ‰¿å—æŠ•è³‡é¢¨éšªçš„èƒ½åŠ›"
)
income_score = income_stability_mapping[income_stability]

# === Question 5: Age-based Adjustment (ç”Ÿå‘½é€±æœŸç†è«–) ===
st.sidebar.markdown("---")
st.sidebar.subheader("Q5. æ‚¨çš„å¹´é½¡ï¼Ÿ")
age = st.sidebar.slider(
    "å¹´é½¡", 
    20, 80, 35,
    help="åŸºæ–¼ç”Ÿå‘½é€±æœŸæŠ•è³‡ç†è«–ï¼Œå¹´è¼•æŠ•è³‡äººå¯æ‰¿å—è¼ƒé«˜é¢¨éšª"
)
# æ”¹è‰¯ç‰ˆ "100-age" ruleï¼šä½¿ç”¨éç·šæ€§å‡½æ•¸
age_score = max(0, min(1, (100 - age) / 60))

# ===============================
# Î¸ è¨ˆç®—ï¼šå­¸è¡“åŠ æ¬Šå¹³å‡
# ===============================
st.sidebar.markdown("---")
st.sidebar.subheader("ğŸ“Š é¢¨éšªåå¥½è¨ˆç®—")

# æ¬Šé‡ä¾†æºï¼š
# - Grable & Lytton (1999): Financial Risk Tolerance Revisited
# - Barsky et al. (1997): Preference Parameters and Behavioral Heterogeneity
weights = {
    'horizon': 0.25,      # æŠ•è³‡æ™‚é–“ç¯„åœ
    'capacity': 0.30,     # é¢¨éšªæ‰¿å—èƒ½åŠ›ï¼ˆSCF æ ¸å¿ƒå•é¡Œï¼Œæ¬Šé‡æœ€é«˜ï¼‰
    'loss': 0.25,         # æå¤±å®¹å¿åº¦ï¼ˆè¡Œç‚ºé‡‘èå­¸é‡é»ï¼‰
    'income': 0.10,       # æ”¶å…¥ç©©å®šæ€§
    'age': 0.10          # å¹´é½¡èª¿æ•´ï¼ˆç”Ÿå‘½é€±æœŸç†è«–ï¼‰
}

theta = (
    weights['horizon'] * horizon_score +
    weights['capacity'] * capacity_score +
    weights['loss'] * loss_score +
    weights['income'] * income_score +
    weights['age'] * age_score
)

theta = np.clip(theta, 0, 1)

# é¡¯ç¤ºä¸»è¦æŒ‡æ¨™
st.sidebar.metric(
    "Î¸ï¼ˆé¢¨éšªåå¥½æŒ‡æ•¸ï¼‰", 
    f"{theta:.3f}",
    help="ç¯„åœ 0-1ï¼Œæ•¸å€¼è¶Šé«˜ä»£è¡¨è¶Šèƒ½æ‰¿å—é¢¨éšª"
)

# é¢¨éšªé¡å‹åˆ†é¡
risk_profile = (
    "ğŸ”µ æ¥µåº¦ä¿å®ˆ" if theta < 0.2 else
    "ğŸŸ¢ ä¿å®ˆ" if theta < 0.4 else
    "ğŸŸ¡ ç©©å¥" if theta < 0.6 else
    "ğŸŸ  ç©æ¥µ" if theta < 0.8 else
    "ğŸ”´ éå¸¸ç©æ¥µ"
)
st.sidebar.info(f"**æ‚¨çš„é¢¨éšªé¡å‹**ï¼š{risk_profile}")

# é¡¯ç¤ºå„é …åˆ†æ•¸ï¼ˆæ‘ºç–Šé¢æ¿ï¼‰
with st.sidebar.expander("ğŸ“‹ æŸ¥çœ‹è©³ç´°è©•åˆ†"):
    st.write(f"**å„é …åˆ†æ•¸æ˜ç´°ï¼š**")
    st.write(f"- æŠ•è³‡æ™‚é–“åˆ†æ•¸ï¼š{horizon_score:.2f} (æ¬Šé‡ {weights['horizon']:.0%})")
    st.write(f"- é¢¨éšªæ‰¿å—åˆ†æ•¸ï¼š{capacity_score:.2f} (æ¬Šé‡ {weights['capacity']:.0%})")
    st.write(f"- æå¤±å®¹å¿åˆ†æ•¸ï¼š{loss_score:.2f} (æ¬Šé‡ {weights['loss']:.0%})")
    st.write(f"- æ”¶å…¥ç©©å®šåˆ†æ•¸ï¼š{income_score:.2f} (æ¬Šé‡ {weights['income']:.0%})")
    st.write(f"- å¹´é½¡èª¿æ•´åˆ†æ•¸ï¼š{age_score:.2f} (æ¬Šé‡ {weights['age']:.0%})")
    st.divider()
    st.write(f"**åŠ æ¬Šè¨ˆç®—ï¼š**")
    st.write(f"Î¸ = {horizon_score:.2f}Ã—{weights['horizon']:.2f} + "
             f"{capacity_score:.2f}Ã—{weights['capacity']:.2f} + "
             f"{loss_score:.2f}Ã—{weights['loss']:.2f} + "
             f"{income_score:.2f}Ã—{weights['income']:.2f} + "
             f"{age_score:.2f}Ã—{weights['age']:.2f}")
    st.write(f"  = **{theta:.3f}**")

# å­¸è¡“åƒè€ƒæ–‡ç»
with st.sidebar.expander("ğŸ“š å­¸è¡“ä¾æ“š"):
    st.caption(
        "**åƒè€ƒæ–‡ç»ï¼š**\n\n"
        "1. Barsky, R. B., Juster, F. T., Kimball, M. S., & Shapiro, M. D. (1997). "
        "Preference parameters and behavioral heterogeneity: An experimental approach in the health and retirement study. "
        "*The Quarterly Journal of Economics*, 112(2), 537-579.\n\n"
        "2. Grable, J., & Lytton, R. H. (1999). "
        "Financial risk tolerance revisited: the development of a risk assessment instrument. "
        "*Financial Services Review*, 8(3), 163-181.\n\n"
        "3. Merton, R. C. (1969). Lifetime portfolio selection under uncertainty: "
        "The continuous-time case. *The Review of Economics and Statistics*, 247-257."
    )

# ===============================
# Î± è¨ˆç®—ï¼ˆå¾ Î¸ æ˜ å°„åˆ° HotIndex æ¬Šé‡ï¼‰
# ===============================
def alpha_from_theta(theta, alpha_min=0.1, alpha_max=0.7):
    """
    å°‡é¢¨éšªåå¥½ Î¸ æ˜ å°„åˆ° HotIndex æ¬Šé‡ Î±
    
    ç†è«–åŸºç¤ï¼š
    - ä¿å®ˆæŠ•è³‡äºº(Î¸ä½)ï¼šæ›´æ³¨é‡å€‹äººåŒ–é©é…ï¼ŒÎ± è¼ƒä½
    - ç©æ¥µæŠ•è³‡äºº(Î¸é«˜)ï¼šæ›´é¡˜æ„è·Ÿéš¨å¸‚å ´ç†±åº¦ï¼ŒÎ± è¼ƒé«˜
    """
    return alpha_min + (alpha_max - alpha_min) * theta

ALPHA_MODEL = alpha_from_theta(theta)

st.sidebar.markdown("---")
st.sidebar.header("âš–ï¸ ç¶œåˆåˆ†æ•¸æ¬Šé‡")
st.sidebar.write(
    f"ğŸ“Œ **HotIndex æ¬Šé‡ï¼ˆÎ±ï¼‰**: {ALPHA_MODEL:.2f}\n\n"
    f"ğŸ“Œ **å€‹äººåŒ–åˆ†æ•¸æ¬Šé‡ï¼ˆ1-Î±ï¼‰**: {1-ALPHA_MODEL:.2f}"
)
st.sidebar.caption(
    f"ğŸ’¡ èªªæ˜ï¼šæ‚¨çš„é¢¨éšªåå¥½ Î¸={theta:.2f}ï¼Œç³»çµ±è‡ªå‹•è¨ˆç®—æœ€é©æ¬Šé‡é…ç½®"
)

# ç§»é™¤æ‰‹å‹• sliderï¼ˆé¿å…æ··æ·†ï¼‰
# st.sidebar.slider("HotIndex æ¬Šé‡ï¼ˆåƒ…ä¾›åƒè€ƒï¼‰", 0.0, 1.0, 0.5, step=0.05)  # åˆªé™¤æ­¤è¡Œ

st.sidebar.markdown("---")
st.sidebar.header("ğŸ“Š æ’åºé¸æ“‡")
sort_option = st.sidebar.selectbox(
    "é¸æ“‡æ’åºä¾æ“š", 
    ["Final Score (HotIndex + å€‹äººåŒ–)", "é¢¨éšªé©é…åˆ†æ•¸ï¼ˆä¾ Î¸ï¼‰"]
)

st.sidebar.header("ğŸ“ˆ Top N ETF é¡¯ç¤º")
TOP_N = st.sidebar.slider("Top N ETF", 1, len(ETF_LIST), 5)

st.sidebar.markdown("---")
st.sidebar.header("ğŸ”„ å³æ™‚æ›´æ–°")
if st.sidebar.button("æ¸…é™¤å¿«å–ä¸¦æ›´æ–°å ±åƒ¹"):
    st.cache_data.clear()
    st.sidebar.success("âœ… å·²æ¸…é™¤å¿«å–ï¼Œå°‡é‡æ–°æŠ“å–å ±åƒ¹")

price_source = st.sidebar.selectbox(
    "æœ€æ–°åƒ¹ä¾†æº", 
    ["auto", "fast_info", "1m"], 
    index=0,
    help="Yahoo Finance è³‡æ–™å¯èƒ½æœ‰å»¶é²"
)
latest_ttl = st.sidebar.slider(
    "æœ€æ–°åƒ¹å¿«å–ç§’æ•¸", 
    0, 120, 10, step=5,
    help="è¼ƒçŸ­çš„å¿«å–æ™‚é–“å¯ç²å¾—æ›´å³æ™‚çš„åƒ¹æ ¼ï¼Œä½†æœƒå¢åŠ  API è«‹æ±‚æ¬¡æ•¸"
)
st.sidebar.caption("âš ï¸ Yahoo è³‡æ–™é€šå¸¸å»¶é² 15 åˆ†é˜ï¼Œè‹¥éœ€å³æ™‚å ±åƒ¹è«‹ä½¿ç”¨åˆ¸å•† API")


# ===============================
# æŠ“å–åƒ¹æ ¼è³‡æ–™
# ===============================

@st.cache_data(ttl=300)  # 5 åˆ†é˜
def fetch_all_price_data(etf_list, benchmark, period="1y"):
    data = {}
    tickers = list(etf_list.keys()) + [benchmark]
    for code in set(tickers):
        try:
            df = yf.Ticker(code).history(period=period)
            if not df.empty and len(df) >= 50:
                data[code] = df
        except Exception:
            data[code] = None
    return data

@st.cache_data(ttl=30)  # 30 ç§’
def fetch_latest_price(code):
    try:
        ticker = yf.Ticker(code)
        fast_info = getattr(ticker, "fast_info", None)
        if fast_info:
            for key in ("last_price", "lastPrice", "regularMarketPrice"):
                price = fast_info.get(key)
                if price:
                    return float(price)
        df = yf.download(code, period="1d", interval="1m", progress=False)
        if df is None or df.empty:
            return None
        return float(df["Close"].iloc[-1])
    except Exception:
        return None

@st.cache_data(ttl=300)  # 5 åˆ†é˜
def fetch_dividend_info(code):
    try:
        ticker = yf.Ticker(code)
        dividends = ticker.dividends
        if dividends is None or dividends.empty:
            return {"æœ€æ–°é…æ¯æ—¥": None, "æœ€è¿‘ä¸€æ¬¡é…æ¯": 0.0, "TTMé…æ¯": 0.0, "TTMæ®–åˆ©ç‡%": 0.0}
        one_year_ago = pd.Timestamp.today() - pd.DateOffset(years=1)
        ttm_dividends = dividends[dividends.index >= one_year_ago]
        latest_date = dividends.index[-1]
        latest_div = float(dividends.iloc[-1])
        price = ticker.history(period="5d")["Close"].iloc[-1]
        ttm_sum = float(ttm_dividends.sum())
        yield_ttm = (ttm_sum / price) * 100 if price > 0 else 0
        return {"æœ€æ–°é…æ¯æ—¥": latest_date.date(), "æœ€è¿‘ä¸€æ¬¡é…æ¯": round(latest_div,3),
                "TTMé…æ¯": round(ttm_sum,3), "TTMæ®–åˆ©ç‡%": round(yield_ttm,2)}
    except Exception:
        return {"æœ€æ–°é…æ¯æ—¥": None, "æœ€è¿‘ä¸€æ¬¡é…æ¯": 0.0, "TTMé…æ¯": 0.0, "TTMæ®–åˆ©ç‡%": 0.0}

# ===============================
# æŒ‡æ¨™è¨ˆç®—
# ===============================
def calc_metrics(df, market_df):
    r = df["Close"].pct_change().dropna()
    mr = market_df["Close"].pct_change().dropna()
    idx = r.index.intersection(mr.index)
    r, mr = r.loc[idx], mr.loc[idx]
    ann_ret = r.mean() * TRADING_DAYS
    ann_vol = r.std() * np.sqrt(TRADING_DAYS)
    sharpe = (ann_ret - RISK_FREE_RATE) / ann_vol if ann_vol>0 else 0
    beta = np.cov(r, mr)[0,1] / np.var(mr)
    return ann_ret*100, ann_vol*100, sharpe, beta

def compute_hot_index(df, window=20):
    volume_ma = df["Volume"].rolling(window).mean().iloc[-1]
    returns = df["Close"].pct_change()
    volatility = returns.rolling(window).std().iloc[-1]
    flow_proxy = (df["Close"]*df["Volume"]).rolling(window).mean().iloc[-1]
    return {"volume_score": volume_ma, "volatility": volatility, "flow_proxy": flow_proxy}

def robust_zscore(series):
    med = np.median(series)
    mad = np.median(np.abs(series - med))
    if mad == 0:
        return pd.Series(0, index=series.index)
    return (series - med)/mad

def compute_personalized_score(ann_ret, ann_vol, sharpe, beta, theta):
    expected_return = 5 + theta * 20
    acceptable_vol = 10 + theta * 25
    ideal_beta = 0.7 + theta * 0.8
    sharpe_fit = min(sharpe/3,1)
    return_fit = np.clip(1 - abs(ann_ret - expected_return)/expected_return,0,1)
    vol_fit = np.clip(1 - ann_vol/acceptable_vol,0,1)
    beta_fit = np.clip(1 - abs(beta - ideal_beta)/ideal_beta,0,1)
    personal_score = np.mean([sharpe_fit, return_fit, vol_fit, beta_fit])
    return {"personal_score": personal_score, "sharpe_fit":sharpe_fit, "return_fit":return_fit,
            "vol_fit":vol_fit,"beta_fit":beta_fit}

def compute_final_score(hot_index_norm, personal_score, alpha):
    return alpha*hot_index_norm + (1-alpha)*personal_score

# ===============================
# ä¸»æµç¨‹
# ===============================
price_data = fetch_all_price_data(ETF_LIST, MARKET_BENCHMARK)
market_df = price_data.get(MARKET_BENCHMARK)

rows=[]
for etf, etf_type in ETF_LIST.items():
    df = price_data.get(etf)
    if df is None or market_df is None:
        continue
    latest_price = fetch_latest_price(etf)
    if latest_price is None:
        latest_price = float(df["Close"].iloc[-1])
    ann_ret, ann_vol, sharpe, beta = calc_metrics(df, market_df)
    comp = compute_personalized_score(ann_ret, ann_vol, sharpe, beta, theta)
    risk_score = comp["vol_fit"]*0.4 + comp["beta_fit"]*0.3 + comp["return_fit"]*0.2 + comp["sharpe_fit"]*0.1
    div_info = fetch_dividend_info(etf)
    hot_metrics = compute_hot_index(df)
    row = {
        "ETF":etf, "é¡å‹":etf_type, "æœ€æ–°åƒ¹":round(latest_price,2),
        "æœ€æ–°é…æ¯æ—¥": div_info["æœ€æ–°é…æ¯æ—¥"], "æœ€è¿‘ä¸€æ¬¡é…æ¯":div_info["æœ€è¿‘ä¸€æ¬¡é…æ¯"],
        "TTMé…æ¯":div_info["TTMé…æ¯"], "TTMæ®–åˆ©ç‡%":div_info["TTMæ®–åˆ©ç‡%"],
        "Sharpe":round(sharpe,2), "Beta":round(beta,2), "å¹´åŒ–å ±é…¬%":round(ann_ret,2),
        "å¹´åŒ–æ³¢å‹•%":round(ann_vol,2), "å€‹äººåŒ–åˆ†æ•¸":round(comp["personal_score"],3),
        "é¢¨éšªé©é…åˆ†æ•¸":round(risk_score,3),
        "volume_score":hot_metrics["volume_score"], "volatility":hot_metrics["volatility"],
        "flow_proxy":hot_metrics["flow_proxy"],
        "Sharpeé©é…":round(comp["sharpe_fit"],2), "å ±é…¬é©é…":round(comp["return_fit"],2),
        "æ³¢å‹•é©é…":round(comp["vol_fit"],2), "Betaé©é…":round(comp["beta_fit"],2)
    }
    rows.append(row)

df_all = pd.DataFrame(rows)
if df_all.empty:
    st.error("âŒ ç„¡æ³•å–å¾—å³æ™‚/æ­·å²å ±åƒ¹è³‡æ–™ï¼Œè«‹ç¨å¾Œé‡è©¦æˆ–ä½¿ç”¨ã€Œæ¸…é™¤å¿«å–ä¸¦æ›´æ–°å ±åƒ¹ã€åŠŸèƒ½ã€‚")
    st.stop()
    
df_all["hot_index"] = df_all["volume_score"] + df_all["flow_proxy"] - df_all["volatility"]
df_all["hot_index_norm"] = robust_zscore(df_all["hot_index"]).fillna(0)

# ===============================
# Î¸ æ’åº & Top-N è¡¨æ ¼
# ===============================
THETA_LIST = [0.0,0.25,0.5,0.75,1.0]
theta_rankings = {}

for t in THETA_LIST:
    rows_theta=[]
    for etf, etf_type in ETF_LIST.items():
        df = price_data.get(etf)
        if df is None or market_df is None:
            continue
        ann_ret, ann_vol, sharpe, beta = calc_metrics(df, market_df)
        comp = compute_personalized_score(ann_ret, ann_vol, sharpe, beta, t)
        final_score = compute_final_score(
            df_all.loc[df_all["ETF"]==etf, "hot_index_norm"].values[0],
            comp["personal_score"],
            ALPHA_MODEL
        )
        base_row = df_all[df_all["ETF"]==etf].iloc[0]
        row = {"ETF":etf,"é¡å‹":etf_type,"Î¸":t,"æœ€æ–°åƒ¹":base_row["æœ€æ–°åƒ¹"],
               "æœ€æ–°é…æ¯æ—¥":base_row["æœ€æ–°é…æ¯æ—¥"],"æœ€è¿‘ä¸€æ¬¡é…æ¯":base_row["æœ€è¿‘ä¸€æ¬¡é…æ¯"],
               "TTMé…æ¯":base_row["TTMé…æ¯"],"TTMæ®–åˆ©ç‡%":base_row["TTMæ®–åˆ©ç‡%"],
               "final_score":final_score,**comp,"hot_index":base_row["hot_index"]}
        rows_theta.append(row)
    df_theta = pd.DataFrame(rows_theta).sort_values("final_score", ascending=False)
    theta_rankings[t] = df_theta

theta_display_closest = min(THETA_LIST, key=lambda x: abs(x-theta))
df_ui = theta_rankings[theta_display_closest].head(TOP_N)

# ===============================
# é›·é”åœ–å°ˆç”¨è³‡æ–™
# ===============================
radar_metrics = ["sharpe_fit", "return_fit", "vol_fit", "beta_fit"]
df_radar = df_ui.copy()
for col in radar_metrics:
    min_v = df_radar[col].min()
    max_v = df_radar[col].max()
    if max_v > min_v:
        df_radar[col] = (df_radar[col] - min_v) / (max_v - min_v)
    else:
        df_radar[col] = 0.5

# ===============================
# Top-N è¡¨æ ¼
# ===============================
st.subheader(f"ğŸ¯ Top {TOP_N} ETF æ’åºï¼ˆÎ¸={round(theta,2)}, Î±={ALPHA_MODEL:.2f}ï¼‰")
st.caption(f"ä¾æ“šæ‚¨çš„é¢¨éšªé¡å‹ **{risk_profile}** è¨ˆç®—çš„æœ€é© ETF çµ„åˆ")

st.dataframe(
    df_ui[["ETF","é¡å‹","æœ€æ–°åƒ¹","æœ€æ–°é…æ¯æ—¥","æœ€è¿‘ä¸€æ¬¡é…æ¯",
           "TTMé…æ¯","TTMæ®–åˆ©ç‡%","final_score","personal_score",
           "sharpe_fit","return_fit","vol_fit","beta_fit","hot_index"]],
    use_container_width=True
)

# ===============================
# Top-N é›·é”åœ– (Plotly)
# ===============================
st.subheader(f"ğŸ•¸ï¸ Top {TOP_N} ETF å¤šæŒ‡æ¨™é›·é”åœ–")
radar_labels = ["Sharpe", "Return", "Volatility", "Beta"]
fig = go.Figure()
for _, row in df_radar.iterrows():
    values = [row[m] for m in radar_metrics]
    values.append(values[0])
    fig.add_trace(go.Scatterpolar(
        r=values,
        theta=radar_labels + [radar_labels[0]],
        fill="toself",
        name=row["ETF"],
        opacity=0.6
    ))
fig.update_layout(
    polar=dict(radialaxis=dict(visible=True, range=[0, 1])),
    showlegend=True,
    margin=dict(l=40, r=40, t=40, b=60)
)
st.plotly_chart(fig, use_container_width=True)

# ===============================
# Top-N æ°£æ³¡åœ– (Altair)
# ===============================
st.subheader(f"ğŸ’­ Top {TOP_N} ETF æ°£æ³¡åœ–ï¼ˆÎ¸={round(theta,2)}ï¼‰")
bubble = alt.Chart(df_ui).mark_circle(opacity=0.7, stroke="black", strokeWidth=0.5).encode(
    x=alt.X("sharpe_fit:Q", title="Sharpe é©é…"),
    y=alt.Y("personal_score:Q", title="å€‹äººåŒ–åˆ†æ•¸"),
    size=alt.Size("beta_fit:Q", title="Beta é©é…", scale=alt.Scale(range=[100,1600])),
    color=alt.Color("é¡å‹:N", title="ETF é¡å‹"),
    tooltip=["ETF","sharpe_fit","return_fit","vol_fit","beta_fit",
             "personal_score","hot_index","final_score"]
)
st.altair_chart(bubble, use_container_width=True)

# ===============================
# V2-1 éç·šæ€§è·é›¢ï¼ˆGaussian Fitï¼‰
# ===============================
def gaussian_fit(x, mu, sigma):
    if sigma <= 0: return 0.0
    return np.exp(-0.5 * ((x - mu) / sigma) ** 2)

def nonlinear_personal_score(row, theta):
    mu_ret = 5 + theta * 20
    mu_vol = 10 + theta * 25
    mu_beta = 0.7 + theta * 0.8
    ret_score = gaussian_fit(row["å¹´åŒ–å ±é…¬%"], mu_ret, mu_ret * 0.5)
    vol_score = gaussian_fit(row["å¹´åŒ–æ³¢å‹•%"], mu_vol, mu_vol * 0.5)
    beta_score = gaussian_fit(row["Beta"], mu_beta, mu_beta * 0.5)
    sharpe_score = np.tanh(row["Sharpe"] / 2)
    return np.mean([ret_score, vol_score, beta_score, sharpe_score])

def multi_period_return(df):
    closes = df["Close"]
    periods = {"3M": 63, "6M": 126, "12M": 252}
    rets = {}
    for k, p in periods.items():
        if len(closes) >= p: rets[k] = closes.iloc[-1] / closes.iloc[-p] - 1
        else: rets[k] = np.nan
    weights = {"3M":0.5,"6M":0.3,"12M":0.2}
    weighted_ret = sum(rets[k]*weights[k] for k in rets if not np.isnan(rets[k]))
    return weighted_ret * 100

def risk_distribution_metrics(df):
    r = df["Close"].pct_change().dropna()
    downside = r[r<0]
    downside_vol = downside.std()*np.sqrt(TRADING_DAYS) if len(downside)>0 else 0
    var_95 = np.percentile(r,5)
    cvar_95 = r[r<=var_95].mean()*100 if len(r[r<=var_95])>0 else 0
    return downside_vol*100, cvar_95

v2_rows=[]
for _, row in df_all.iterrows():
    etf = row["ETF"]
    df = price_data.get(etf)
    if df is None: continue
    v2_score = nonlinear_personal_score(row, theta)
    mp_ret = multi_period_return(df)
    downside_vol, cvar_95 = risk_distribution_metrics(df)
    v2_rows.append({
        "ETF":etf,
        "V2_éç·šæ€§åˆ†æ•¸": round(v2_score,3),
        "V2_å¤šæœŸé–“åŠ æ¬Šå ±é…¬%": round(mp_ret,2),
        "V2_ä¸‹è¡Œæ³¢å‹•%": round(downside_vol,2),
        "V2_CVaR_95%": round(cvar_95,2)
    })

df_v2 = pd.DataFrame(v2_rows)
df_all = df_all.merge(df_v2, on="ETF", how="left")

st.divider()
st.subheader("ğŸ§ª V2 é€²éšåˆ†æï¼ˆéç·šæ€§ Ã— å¤šæœŸé–“ Ã— é¢¨éšªåˆ†å¸ƒï¼‰")
st.caption("âš ï¸ ä»¥ä¸‹ç‚º V2 åˆ†ææ¨¡çµ„ï¼Œä¸å½±éŸ¿ä»»ä½• V1 æ’åºèˆ‡æ¨è–¦çµæœ")
st.dataframe(
    df_all[["ETF","V2_éç·šæ€§åˆ†æ•¸","V2_å¤šæœŸé–“åŠ æ¬Šå ±é…¬%",
            "V2_ä¸‹è¡Œæ³¢å‹•%","V2_CVaR_95%"]],
    use_container_width=True
)
