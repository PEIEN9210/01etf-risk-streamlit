# -*- coding: utf-8 -*-
"""app.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Y1jRJvzhlUjdd66vnUOBj57YzwXHYc1s
"""

# app.py
# -*- coding: utf-8 -*-

import streamlit as st
import pandas as pd
import numpy as np
import yfinance as yf
import altair as alt
from datetime import datetime, timedelta
from scipy.stats import spearmanr

# ===============================
# åŸºæœ¬è¨­å®š
# ===============================
st.set_page_config(page_title="å°ç£ ETF å€‹äººåŒ–æ¨è–¦ç³»çµ±", layout="wide")
st.title("ğŸ“Š å°ç£ ETF å€‹äººåŒ– + ç†±é–€ ETF å¤šæº–å‰‡è³‡ç”¢æ’åºæ¡†æ¶ (åƒ…ä¾›åƒè€ƒï¼Œä¸è² æŠ•è³‡é¢¨éšª:)")

TRADING_DAYS = 252
RISK_FREE_RATE = 0.01  # ç„¡é¢¨éšªåˆ©ç‡

# ===============================
# ETF Universe & å¸‚å ´åŸºæº–
# ===============================
ETF_LIST = {
    "0050.TW": "è‚¡ç¥¨å‹",
    "006208.TW": "è‚¡ç¥¨å‹",
    "00692.TW": "è‚¡ç¥¨å‹",
    "00757.TW": "è‚¡ç¥¨å‹",
    "0056.TW": "é«˜è‚¡æ¯å‹",
    "00878.TW": "é«˜è‚¡æ¯å‹",
    "00919.TW": "é«˜è‚¡æ¯å‹",
}
MARKET_BENCHMARK = "0050.TW"

# ===============================
# Sidebarï¼šä½¿ç”¨è€…è¨­å®š
# ===============================
st.sidebar.header("ğŸ‘¤ æŠ•è³‡äººé¢¨éšªè¨­å®š")
age = st.sidebar.slider("å¹´é½¡", 20, 80, 35, key="age_slider")
horizon = st.sidebar.slider("æŠ•è³‡å¹´é™ï¼ˆå¹´ï¼‰", 1, 30, 10, key="horizon_slider")
loss_tol = st.sidebar.slider("å¯æ¥å—æœ€å¤§æå¤± (%)", 0, 50, 20, key="loss_slider")
reaction = st.sidebar.radio("å¸‚å ´ä¸‹è·Œ 20% æ™‚", ["è³£å‡º", "è§€æœ›", "åŠ ç¢¼"], key="reaction_radio")

# è¨ˆç®— Î¸
theta = ((80 - age)/60 + horizon/30 + loss_tol/50 + {"è³£å‡º":0,"è§€æœ›":0.5,"åŠ ç¢¼":1}[reaction])/4
theta = np.clip(theta, 0, 1)
st.sidebar.metric("Î¸ï¼ˆé¢¨éšªåå¥½æŒ‡æ•¸ï¼‰", round(theta, 2))

# Î± ç”± Î¸ å…§ç”Ÿæ±ºå®š
def alpha_from_theta(theta, alpha_min=0.1, alpha_max=0.7):
    return alpha_min + (alpha_max - alpha_min) * theta

ALPHA_MODEL = alpha_from_theta(theta)

# Sidebar é¡¯ç¤ºå…§ç”Ÿ Î±ï¼ˆç´”è³‡è¨Šï¼‰
st.sidebar.header("âš–ï¸ ç¶œåˆåˆ†æ•¸æ¬Šé‡")
st.sidebar.write(
    f"ğŸ“Œ HotIndex æ¬Šé‡ (å…§ç”Ÿ Î±ï¼Œä¾ Î¸ è¨ˆç®—): {ALPHA_MODEL:.2f}\n"
    f"ğŸ“Œ å€‹äººåŒ–åˆ†æ•¸æ¬Šé‡: {1-ALPHA_MODEL:.2f}\n"
    "(æ‰‹å‹• slider Î± åƒ…ä¾›åƒè€ƒï¼Œä¸å½±éŸ¿æ’åº)"
)
st.sidebar.slider(
    "HotIndex æ¬Šé‡ï¼ˆåƒ…ä¾›åƒè€ƒï¼‰",
    0.0, 1.0, 0.5, step=0.05, key="alpha_slider"
)

# æ’åºé¸é …
st.sidebar.header("ğŸ“Š æ’åºé¸æ“‡")
sort_option = st.sidebar.selectbox(
    "é¸æ“‡æ’åºä¾æ“š",
    ["Final Score (HotIndex + å€‹äººåŒ–)", "é¢¨éšªé©é…åˆ†æ•¸ï¼ˆä¾ Î¸ï¼‰"],
    key="sort_option"
)

# Top N é¡¯ç¤º
st.sidebar.header("ğŸ“ˆ Top N ETF é¡¯ç¤º")
TOP_N = st.sidebar.slider("Top N ETF", 1, len(ETF_LIST), 5, key="topn_slider")

# ===============================
# æŠ“å–åƒ¹æ ¼è³‡æ–™ï¼ˆå«æ¯æ—¥è‡ªå‹•åˆ·æ–°ï¼‰
# ===============================
@st.cache_data(ttl=86400)
def fetch_price_data(code, period="1y"):
    df = yf.Ticker(code).history(period=period)
    if df.empty or len(df) < 50:
        return None
    return df

@st.cache_data(ttl=86400)
def fetch_all_price_data(etf_list, benchmark, period="1y"):
    data = {}
    tickers = list(etf_list.keys()) + [benchmark]

    for code in set(tickers):
        try:
            df = yf.Ticker(code).history(period=period)
            if not df.empty and len(df) >= 50:
                data[code] = df
        except Exception as e:
            data[code] = None
    return data
# ===============================
# é…æ¯è³‡æ–™æŠ“å–ï¼ˆå¢é‡ï¼‰
# ===============================
@st.cache_data(ttl=86400)
def fetch_dividend_info(code):
    """
    å›å‚³ï¼š
    - æœ€æ–°é…æ¯æ—¥
    - æœ€è¿‘ä¸€æ¬¡é…æ¯
    - TTM å¹´åŒ–é…æ¯
    - TTM æ®–åˆ©ç‡ï¼ˆ%ï¼‰
    """
    try:
        ticker = yf.Ticker(code)
        dividends = ticker.dividends

        if dividends is None or dividends.empty:
            return {
                "æœ€æ–°é…æ¯æ—¥": None,
                "æœ€è¿‘ä¸€æ¬¡é…æ¯": 0.0,
                "TTMé…æ¯": 0.0,
                "TTMæ®–åˆ©ç‡%": 0.0
            }

        # æœ€è¿‘ 12 å€‹æœˆé…æ¯
        one_year_ago = pd.Timestamp.today() - pd.DateOffset(years=1)
        ttm_dividends = dividends[dividends.index >= one_year_ago]

        latest_date = dividends.index[-1]
        latest_div = float(dividends.iloc[-1])
        ttm_sum = float(ttm_dividends.sum())

        # æœ€æ–°åƒ¹æ ¼ï¼ˆç”¨æ–¼æ®–åˆ©ç‡ï¼‰
        price = ticker.history(period="5d")["Close"].iloc[-1]
        yield_ttm = (ttm_sum / price) * 100 if price > 0 else 0

        return {
            "æœ€æ–°é…æ¯æ—¥": latest_date.date(),
            "æœ€è¿‘ä¸€æ¬¡é…æ¯": round(latest_div, 3),
            "TTMé…æ¯": round(ttm_sum, 3),
            "TTMæ®–åˆ©ç‡%": round(yield_ttm, 2)
        }

    except Exception:
        return {
            "æœ€æ–°é…æ¯æ—¥": None,
            "æœ€è¿‘ä¸€æ¬¡é…æ¯": 0.0,
            "TTMé…æ¯": 0.0,
            "TTMæ®–åˆ©ç‡%": 0.0
        }

# ===============================
# æŒ‡æ¨™è¨ˆç®—
# ===============================
def calc_metrics(df, market_df):
    r = df["Close"].pct_change().dropna()
    mr = market_df["Close"].pct_change().dropna()
    idx = r.index.intersection(mr.index)
    r, mr = r.loc[idx], mr.loc[idx]

    ann_ret = r.mean() * TRADING_DAYS
    ann_vol = r.std() * np.sqrt(TRADING_DAYS)
    sharpe = (ann_ret - RISK_FREE_RATE) / ann_vol if ann_vol > 0 else 0
    beta = np.cov(r, mr)[0, 1] / np.var(mr)
    return ann_ret * 100, ann_vol * 100, sharpe, beta

def compute_hot_index(df, window=20):
    volume_ma = df["Volume"].rolling(window).mean().iloc[-1]
    returns = df["Close"].pct_change()
    volatility = returns.rolling(window).std().iloc[-1]
    flow_proxy = (df["Close"] * df["Volume"]).rolling(window).mean().iloc[-1]
    return {"volume_score": volume_ma, "volatility": volatility, "flow_proxy": flow_proxy}

def robust_zscore(series):
    med = np.median(series)
    mad = np.median(np.abs(series - med))
    if mad == 0:
        return pd.Series(0, index=series.index)
    return (series - med) / mad

# ===============================
# ä¸»æµç¨‹ï¼šè¨ˆç®— ETF åˆ†æ•¸
# ===============================
price_data = fetch_all_price_data(ETF_LIST, MARKET_BENCHMARK)
market_df = price_data.get(MARKET_BENCHMARK)

rows = []

for etf, etf_type in ETF_LIST.items():
    df = price_data.get(etf)
    if df is None or market_df is None:
        continue

    ann_ret, ann_vol, sharpe, beta = calc_metrics(df, market_df)

    # å€‹äººåŒ–é©é…
    expected_return = 5 + theta * 20
    acceptable_vol = 10 + theta * 25
    ideal_beta = 0.7 + theta * 0.8

    sharpe_fit = min(sharpe / 3, 1)
    return_fit = np.clip(1 - abs(ann_ret - expected_return) / expected_return, 0, 1)
    vol_fit = np.clip(1 - ann_vol / acceptable_vol, 0, 1)
    beta_fit = np.clip(1 - abs(beta - ideal_beta) / ideal_beta, 0, 1)

    # é¢¨éšªé©é…åˆ†æ•¸ï¼ˆåŠ æ¬Šï¼‰
    risk_score = vol_fit * 0.4 + beta_fit * 0.3 + return_fit * 0.2 + sharpe_fit * 0.1
    personal_score = np.mean([sharpe_fit, return_fit, vol_fit, beta_fit])

    # HotIndex
    hot_metrics = compute_hot_index(df)
div_info = fetch_dividend_info(etf)

row = {
    "ETF": etf,
    "é¡å‹": etf_type,
    "æœ€æ–°åƒ¹": round(df["Close"].iloc[-1], 2),

    # ğŸ†• é…æ¯è³‡è¨Šï¼ˆå¢é‡ï¼‰
    "æœ€æ–°é…æ¯æ—¥": div_info["æœ€æ–°é…æ¯æ—¥"],
    "æœ€è¿‘ä¸€æ¬¡é…æ¯": div_info["æœ€è¿‘ä¸€æ¬¡é…æ¯"],
    "TTMé…æ¯": div_info["TTMé…æ¯"],
    "TTMæ®–åˆ©ç‡%": div_info["TTMæ®–åˆ©ç‡%"],

    "Sharpe": round(sharpe, 2),
    "Beta": round(beta, 2),
    "å¹´åŒ–å ±é…¬%": round(ann_ret, 2),
    "å¹´åŒ–æ³¢å‹•%": round(ann_vol, 2),
    "å€‹äººåŒ–åˆ†æ•¸": round(personal_score, 3),
    "é¢¨éšªé©é…åˆ†æ•¸": round(risk_score, 3),
    "volume_score": hot_metrics["volume_score"],
    "volatility": hot_metrics["volatility"],
    "flow_proxy": hot_metrics["flow_proxy"],
    "Sharpeé©é…": round(sharpe_fit, 2),
    "å ±é…¬é©é…": round(return_fit, 2),
    "æ³¢å‹•é©é…": round(vol_fit, 2),
    "Betaé©é…": round(beta_fit, 2)
}
rows = []

for etf, etf_type in ETF_LIST.items():
    df = price_data.get(etf)
    if df is None or market_df is None:
        continue

    ann_ret, ann_vol, sharpe, beta = calc_metrics(df, market_df)

    # å€‹äººåŒ–é©é…
    expected_return = 5 + theta * 20
    acceptable_vol = 10 + theta * 25
    ideal_beta = 0.7 + theta * 0.8

    sharpe_fit = min(sharpe / 3, 1)
    return_fit = np.clip(1 - abs(ann_ret - expected_return) / expected_return, 0, 1)
    vol_fit = np.clip(1 - ann_vol / acceptable_vol, 0, 1)
    beta_fit = np.clip(1 - abs(beta - ideal_beta) / ideal_beta, 0, 1)

    risk_score = (
        vol_fit * 0.4
        + beta_fit * 0.3
        + return_fit * 0.2
        + sharpe_fit * 0.1
    )
    personal_score = np.mean([sharpe_fit, return_fit, vol_fit, beta_fit])

    # HotIndex
    hot_metrics = compute_hot_index(df)

    # ğŸ†• é…æ¯è³‡è¨Šï¼ˆä¸€å®šè¦åœ¨ loop è£¡ï¼‰
    div_info = fetch_dividend_info(etf)

    row = {
        "ETF": etf,
        "é¡å‹": etf_type,
        "æœ€æ–°åƒ¹": round(df["Close"].iloc[-1], 2),

        # é…æ¯æ¬„ä½
        "æœ€æ–°é…æ¯æ—¥": div_info["æœ€æ–°é…æ¯æ—¥"],
        "æœ€è¿‘ä¸€æ¬¡é…æ¯": div_info["æœ€è¿‘ä¸€æ¬¡é…æ¯"],
        "TTMé…æ¯": div_info["TTMé…æ¯"],
        "TTMæ®–åˆ©ç‡%": div_info["TTMæ®–åˆ©ç‡%"],

        "Sharpe": round(sharpe, 2),
        "Beta": round(beta, 2),
        "å¹´åŒ–å ±é…¬%": round(ann_ret, 2),
        "å¹´åŒ–æ³¢å‹•%": round(ann_vol, 2),
        "å€‹äººåŒ–åˆ†æ•¸": round(personal_score, 3),
        "é¢¨éšªé©é…åˆ†æ•¸": round(risk_score, 3),
        "volume_score": hot_metrics["volume_score"],
        "volatility": hot_metrics["volatility"],
        "flow_proxy": hot_metrics["flow_proxy"],
        "Sharpeé©é…": round(sharpe_fit, 2),
        "å ±é…¬é©é…": round(return_fit, 2),
        "æ³¢å‹•é©é…": round(vol_fit, 2),
        "Betaé©é…": round(beta_fit, 2),
    }

    rows.append(row)
    # ===============================
# å»ºç«‹ df_allï¼ˆHotIndex æ­£è¦åŒ–æ¯è¡¨ï¼‰
# ===============================
df_all = pd.DataFrame(rows)

# HotIndex åŸå§‹å€¼
df_all["hot_index"] = (
    df_all["volume_score"]
    + df_all["flow_proxy"]
    - df_all["volatility"]
)

# Robust Z-score æ­£è¦åŒ–ï¼ˆé¿å…æ¥µç«¯å€¼ï¼‰
df_all["hot_index_norm"] = robust_zscore(df_all["hot_index"])

# ç¼ºå¤±ä¿è­·
df_all["hot_index_norm"] = df_all["hot_index_norm"].fillna(0)
# ===============================
# è¨ˆç®—å€‹äººåŒ–åˆ†æ•¸ componentï¼ˆÎ¸ é©…å‹•ï¼‰
# ===============================
def compute_personalized_score(ann_ret, ann_vol, sharpe, beta, theta):
    expected_return = 5 + theta * 20
    acceptable_vol = 10 + theta * 25
    ideal_beta = 0.7 + theta * 0.8

    sharpe_fit = min(sharpe / 3, 1)
    return_fit = np.clip(1 - abs(ann_ret - expected_return) / expected_return, 0, 1)
    vol_fit = np.clip(1 - ann_vol / acceptable_vol, 0, 1)
    beta_fit = np.clip(1 - abs(beta - ideal_beta) / ideal_beta, 0, 1)

    personal_score = np.mean([sharpe_fit, return_fit, vol_fit, beta_fit])

    return {
        "personal_score": personal_score,
        "sharpe_fit": sharpe_fit,
        "return_fit": return_fit,
        "vol_fit": vol_fit,
        "beta_fit": beta_fit
    }

def compute_final_score(hot_index_norm, personal_score, alpha):
    return alpha * hot_index_norm + (1 - alpha) * personal_score

# ===============================
# æ”¯æ´ä¸åŒ Î¸ çš„å€‹äººåŒ–æ’åºï¼ˆRanking Robustnessï¼‰
# ===============================
THETA_LIST = [0.0, 0.25, 0.5, 0.75, 1.0]
theta_rankings = {}

for t in THETA_LIST:
    rows = []
    for etf, etf_type in ETF_LIST.items():
        df = price_data.get(etf)
        if df is None or market_df is None:
            continue

        ann_ret, ann_vol, sharpe, beta = calc_metrics(df, market_df)
        comp = compute_personalized_score(ann_ret, ann_vol, sharpe, beta, t)
        hot_metrics = compute_hot_index(df)

        # ä½¿ç”¨å…§ç”Ÿ Î±
        final_score = compute_final_score(
            df_all.loc[df_all["ETF"] == etf, "hot_index_norm"].values[0],
            comp["personal_score"],
            alpha=ALPHA_MODEL
        )

       base_row = df_all[df_all["ETF"] == etf].iloc[0]

     row = {
         "ETF": etf,
        "é¡å‹": etf_type,
        "Î¸": t,
        "æœ€æ–°åƒ¹": base_row["æœ€æ–°åƒ¹"],
        "æœ€æ–°é…æ¯æ—¥": base_row["æœ€æ–°é…æ¯æ—¥"],
        "æœ€è¿‘ä¸€æ¬¡é…æ¯": base_row["æœ€è¿‘ä¸€æ¬¡é…æ¯"],
        "TTMé…æ¯": base_row["TTMé…æ¯"],
        "TTMæ®–åˆ©ç‡%": base_row["TTMæ®–åˆ©ç‡%"],
        "final_score": final_score,
        **comp,
        "hot_index": base_row["hot_index"]
        }
        rows.append(row)

    df_theta = pd.DataFrame(rows)
    df_theta = df_theta.sort_values("final_score", ascending=False)
    theta_rankings[t] = df_theta

# ===============================
# Sidebar Î¸ å°æ‡‰æœ€è¿‘é„° THETA_LIST
# ===============================
theta_display_closest = min(THETA_LIST, key=lambda x: abs(x - theta))
df_ui = theta_rankings[theta_display_closest].head(TOP_N)

# ===============================
# UI / Top-N å±•ç¤º
# ===============================
st.subheader(f"ğŸ¯ Top {TOP_N} ETF æ’åºï¼ˆÎ¸={round(theta, 2)}, final_scoreï¼‰")
st.dataframe(
    df_ui[[
        "ETF", "é¡å‹",
        "æœ€æ–°åƒ¹",
        "æœ€æ–°é…æ¯æ—¥",
        "æœ€è¿‘ä¸€æ¬¡é…æ¯",
        "TTMé…æ¯",
        "TTMæ®–åˆ©ç‡%",
        "final_score",
        "personal_score",
        "sharpe_fit",
        "return_fit",
        "vol_fit",
        "beta_fit",
        "hot_index"
    ]],
    use_container_width=True
)

# ===============================
# é›·é”åœ–
# ===============================
st.subheader(f"ğŸ“¡ Top {TOP_N} ETF é›·é”åœ–ï¼ˆÎ¸={round(theta, 2)}ï¼‰")
metrics = ["sharpe_fit", "return_fit", "vol_fit", "beta_fit"]
radar = df_ui.melt(id_vars="ETF", value_vars=metrics, var_name="æŒ‡æ¨™", value_name="å€¼")
radar["order"] = radar["æŒ‡æ¨™"].map({m: i for i, m in enumerate(metrics)})
radar["è§’åº¦"] = radar["order"] * 2 * np.pi / len(metrics)
radar["x"] = radar["å€¼"] * np.cos(radar["è§’åº¦"])
radar["y"] = radar["å€¼"] * np.sin(radar["è§’åº¦"])
radar_closed = pd.concat(
    [radar, radar.groupby("ETF").apply(lambda d: d.iloc[[0]]).reset_index(drop=True)],
    ignore_index=True
)

area = alt.Chart(radar_closed).mark_area(opacity=0.3).encode(
    x=alt.X("x:Q", axis=None),
    y=alt.Y("y:Q", axis=None),
    color="ETF:N",
    detail="ETF:N",
    order="order:Q",
    tooltip=["ETF", "æŒ‡æ¨™", "å€¼"]
)
line = alt.Chart(radar_closed).mark_line().encode(
    x="x:Q",
    y="y:Q",
    color="ETF:N",
    detail="ETF:N",
    order="order:Q"
)
labels = pd.DataFrame({
    "æŒ‡æ¨™": metrics,
    "x": [1.2 * np.cos(i * 2 * np.pi / len(metrics)) for i in range(len(metrics))],
    "y": [1.2 * np.sin(i * 2 * np.pi / len(metrics)) for i in range(len(metrics))]
})
text = alt.Chart(labels).mark_text(fontSize=12).encode(x="x:Q", y="y:Q", text="æŒ‡æ¨™:N")
st.altair_chart(area + line + text, use_container_width=True)

# ===============================
# æ°£æ³¡åœ–
# ===============================
st.subheader(f"ğŸ’­ Top {TOP_N} ETF æ°£æ³¡åœ–ï¼ˆÎ¸={round(theta, 2)}ï¼‰")
bubble = alt.Chart(df_ui).mark_circle(opacity=0.7, stroke="black", strokeWidth=0.5).encode(
    x=alt.X("sharpe_fit:Q", title="Sharpe é©é…"),
    y=alt.Y("personal_score:Q", title="å€‹äººåŒ–åˆ†æ•¸"),
    size=alt.Size("beta_fit:Q", title="Beta é©é…", scale=alt.Scale(range=[100, 1600])),
    color=alt.Color("é¡å‹:N", title="ETF é¡å‹"),
    tooltip=["ETF", "sharpe_fit", "return_fit", "vol_fit", "beta_fit",
             "personal_score", "hot_index", "final_score"]
)
st.altair_chart(bubble, use_container_width=True)
